{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 20:45:18.181930: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 20:45:18.860642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070 Ti, compute capability 8.6\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 20:45:19.899235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:19.923246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:19.923305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:19.923757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# Allow memory growth for the GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# Activate mixed precision\n",
    "from keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "from dino import create_dino_model, Sequential, layers, ResNet, ResnetEnum"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:45:20.761825300Z",
     "start_time": "2023-11-28T17:45:17.991902300Z"
    }
   },
   "id": "518eb909c09ff88e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:45:20.806902300Z",
     "start_time": "2023-11-28T17:45:20.764832500Z"
    }
   },
   "id": "81e8d22df72bde75"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38992 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# All images under this path will be used for training\n",
    "dataset_path = \"/mnt/c/Users/mnusr/PycharmProjects/hcc_tests/big_image_example/processed_2\"\n",
    "\n",
    "# All images under this path will be used for testing\n",
    "test_dataset_path = \"/mnt/c/Users/mnusr/PycharmProjects/hcc_tests/datasets/hcc_vs_periph\"\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    label_mode=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(2048, 2048),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    interpolation=\"bicubic\",\n",
    ").prefetch(tf.data.AUTOTUNE).take(32 * 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:47:56.024757700Z",
     "start_time": "2023-11-28T17:45:37.775435200Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2809 files belonging to 2 classes.\n",
      "Using 2248 files for training.\n",
      "Found 2809 files belonging to 2 classes.\n",
      "Using 561 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dataset_path,\n",
    "    label_mode='binary',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(512, 512),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    interpolation=\"bicubic\",\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dataset_path,\n",
    "    label_mode='binary',\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(512, 512),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    interpolation=\"bicubic\",\n",
    ").prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:31:28.807813800Z",
     "start_time": "2023-11-28T17:31:17.066957500Z"
    }
   },
   "id": "3d53243145b464dc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total zero labels: 1339\n",
      "Total one labels: 909\n",
      "Total labels: 2248\n",
      "Class weight: {0: <tf.Tensor: shape=(), dtype=float64, numpy=0.4043594306049822>, 1: <tf.Tensor: shape=(), dtype=float64, numpy=0.5956405693950177>}\n"
     ]
    }
   ],
   "source": [
    "# Zero label count\n",
    "total_zero_labels = 0\n",
    "total_one_labels = 0\n",
    "for batch in validation_dataset:\n",
    "    total_zero_labels += tf.math.count_nonzero(batch[1] == 0)\n",
    "    total_one_labels += tf.math.count_nonzero(batch[1] == 1)\n",
    "\n",
    "print(f\"Total zero labels: {total_zero_labels}\")\n",
    "print(f\"Total one labels: {total_one_labels}\")\n",
    "print(f\"Total labels: {total_zero_labels + total_one_labels}\")\n",
    "class_weight = {0: total_one_labels / (total_zero_labels + total_one_labels),\n",
    "                1: total_zero_labels / (total_zero_labels + total_one_labels)}\n",
    "print(f\"Class weight: {class_weight}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:32:03.526333100Z",
     "start_time": "2023-11-28T17:31:28.813325200Z"
    }
   },
   "id": "ae4e02e362a1cb27"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total zero labels: 331\n",
      "Total one labels: 230\n",
      "Total labels: 561\n",
      "Class weight: {0: <tf.Tensor: shape=(), dtype=float64, numpy=0.40998217468805703>, 1: <tf.Tensor: shape=(), dtype=float64, numpy=0.5900178253119429>}\n"
     ]
    }
   ],
   "source": [
    "# Zero label count\n",
    "total_zero_labels = 0\n",
    "total_one_labels = 0\n",
    "for batch in test_dataset:\n",
    "    total_zero_labels += tf.math.count_nonzero(batch[1] == 0)\n",
    "    total_one_labels += tf.math.count_nonzero(batch[1] == 1)\n",
    "\n",
    "print(f\"Total zero labels: {total_zero_labels}\")\n",
    "print(f\"Total one labels: {total_one_labels}\")\n",
    "print(f\"Total labels: {total_zero_labels + total_one_labels}\")\n",
    "class_weight_test = {0: total_one_labels / (total_zero_labels + total_one_labels),\n",
    "                     1: total_zero_labels / (total_zero_labels + total_one_labels)}\n",
    "print(f\"Class weight: {class_weight_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:32:10.690299600Z",
     "start_time": "2023-11-28T17:32:03.522331300Z"
    }
   },
   "id": "84f938283df6e34b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 20:45:26.140004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:26.140109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:26.140151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:26.308201: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:26.308273: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:26.308282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-28 20:45:26.308322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2d:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-28 20:45:26.308347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5572 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "teacher = ResNet(\n",
    "    rescale=True,\n",
    "    input_shape=(None, None, 3),\n",
    "    batch_count=BATCH_SIZE,\n",
    "    activations=\"gelu\",\n",
    "    resnet_version=ResnetEnum.resnet16,\n",
    ")\n",
    "\n",
    "student = ResNet(\n",
    "    rescale=True,\n",
    "    input_shape=(None, None, 3),\n",
    "    batch_count=BATCH_SIZE,\n",
    "    activations=\"gelu\",\n",
    "    resnet_version=ResnetEnum.resnet16,\n",
    ")\n",
    "\n",
    "model = create_dino_model(\n",
    "    student,\n",
    "    teacher,\n",
    "    global_crop_size=512,\n",
    "    local_crop_size=256,\n",
    "    local_augmentation_count=4,\n",
    "    network_momentum=0.99995,\n",
    "    teacher_temperature=0.01\n",
    ")\n",
    "\n",
    "schedule = tf.keras.optimizers.schedules.CosineDecay(0.00001, decay_steps=152 * 80, alpha=1e-6, warmup_target=0.00009,\n",
    "                                                     warmup_steps=152 * 150)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(schedule,weight_decay=0.04)#,clipnorm=3)\n",
    "\n",
    "scaled_optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "\n",
    "model.compile(optimizer=scaled_optimizer, run_eagerly=False, jit_compile=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:45:28.038810Z",
     "start_time": "2023-11-28T17:45:26.124170600Z"
    }
   },
   "id": "c0d84107533ad25e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "INFO:tensorflow:Running stacked flow\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/mnt/c/Users/mnusr/PycharmProjects/tf_model_implementations/tf_model_implementations/cv/self_supervised/dino.py\", line 268, in train_step\n        tf.cond(\n    File \"/mnt/c/Users/mnusr/PycharmProjects/tf_model_implementations/tf_model_implementations/cv/self_supervised/dino.py\", line 281, in apply_accumulated_gradients\n        variable.assign(tf.math.divide(variable, tf.cast(self.accumulation_steps, tf.float32)))\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras_core/src/backend/common/variables.py\", line 119, in assign\n        raise ValueError(\n\n    ValueError: The shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(64,), Received: value.shape=(1, 64). Target variable: <KerasVariable shape=(64,), dtype=float32, path=variable_2>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m student\u001B[38;5;241m.\u001B[39mtrainable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m500\u001B[39;49m\n\u001B[1;32m      5\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/tmp/__autograph_generated_filefcvsj1dm.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/mnt/c/Users/mnusr/PycharmProjects/tf_model_implementations/tf_model_implementations/cv/self_supervised/dino.py:268\u001B[0m, in \u001B[0;36mDino.train_step\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_accumulator)):\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_accumulator[j]\u001B[38;5;241m.\u001B[39massign_add(gradients[j])\n\u001B[0;32m--> 268\u001B[0m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcond\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mequal\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccumulation_step_counter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccumulation_steps\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_accumulated_gradients\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[1;32m    272\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m: loss}\n",
      "File \u001B[0;32m/mnt/c/Users/mnusr/PycharmProjects/tf_model_implementations/tf_model_implementations/cv/self_supervised/dino.py:281\u001B[0m, in \u001B[0;36mDino.apply_accumulated_gradients\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_accumulated_gradients\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m variable \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_accumulator:\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;66;03m# Divide the accumulated gradients by the number of accumulation steps\u001B[39;00m\n\u001B[0;32m--> 281\u001B[0m         \u001B[43mvariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massign\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdivide\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccumulation_steps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mapply_gradients(\n\u001B[1;32m    285\u001B[0m         \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgradient_accumulator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstudent_encoder\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[1;32m    286\u001B[0m     )\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccumulation_step_counter\u001B[38;5;241m.\u001B[39massign(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/keras_core/src/backend/common/variables.py:119\u001B[0m, in \u001B[0;36mKerasVariable.assign\u001B[0;34m(self, value)\u001B[0m\n\u001B[1;32m    117\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_to_tensor(value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m shape_equal(value\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape):\n\u001B[0;32m--> 119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    120\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe shape of the target variable and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    121\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe shape of the target value in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`variable.assign(value)` must match. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    123\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvariable.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    124\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived: value.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    125\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget variable: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    126\u001B[0m     )\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m in_stateless_scope():\n\u001B[1;32m    128\u001B[0m     scope \u001B[38;5;241m=\u001B[39m get_stateless_scope()\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/mnt/c/Users/mnusr/PycharmProjects/tf_model_implementations/tf_model_implementations/cv/self_supervised/dino.py\", line 268, in train_step\n        tf.cond(\n    File \"/mnt/c/Users/mnusr/PycharmProjects/tf_model_implementations/tf_model_implementations/cv/self_supervised/dino.py\", line 281, in apply_accumulated_gradients\n        variable.assign(tf.math.divide(variable, tf.cast(self.accumulation_steps, tf.float32)))\n    File \"/home/nusret/miniconda3/envs/tf/lib/python3.11/site-packages/keras_core/src/backend/common/variables.py\", line 119, in assign\n        raise ValueError(\n\n    ValueError: The shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(64,), Received: value.shape=(1, 64). Target variable: <KerasVariable shape=(64,), dtype=float32, path=variable_2>\n"
     ]
    }
   ],
   "source": [
    "student.trainable = True\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=500\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:48:30.344155500Z",
     "start_time": "2023-11-28T17:48:09.011370700Z"
    }
   },
   "id": "8cd3a99b43090877"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "student.trainable = False\n",
    "\n",
    "model_st = Sequential(\n",
    "    [\n",
    "        student,\n",
    "        layers.Dense(1),\n",
    "        layers.Activation(\"sigmoid\", dtype=tf.float32)\n",
    "    ])\n",
    "\n",
    "optimizer_st = tf.keras.optimizers.Adam(0.00001)\n",
    "\n",
    "scaled_optimizer_st = mixed_precision.LossScaleOptimizer(optimizer_st)\n",
    "\n",
    "model_st.compile(optimizer=scaled_optimizer_st, run_eagerly=False, jit_compile=True,\n",
    "                 metrics=[\n",
    "                     tf.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                     tf.metrics.AUC(name='auc'),\n",
    "                     tf.metrics.Precision(name='precision'),\n",
    "                     tf.metrics.Recall(name='recall'),\n",
    "                 ],\n",
    "                 loss=\"binary_crossentropy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:32:12.563393400Z",
     "start_time": "2023-11-28T17:32:12.556371Z"
    }
   },
   "id": "b05f733ab6c83856"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_st.fit(\n",
    "    validation_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=20,\n",
    "    initial_epoch=0,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    ,\n",
    "    class_weight=class_weight\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.557370900Z"
    }
   },
   "id": "6b98662d0877d3e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model.save('dino')\n",
    "model_st.save('dino_student')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.558875700Z"
    }
   },
   "id": "6d45831eb8d28aeb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try with imagenet pretrained resnet50\n",
    "model_pt = tf.keras.applications.resnet_rs.ResNetRS50(pooling='avg',input_shape=[512,512,3],include_top=False)\n",
    "model_pt.trainable = False\n",
    "model_pt = Sequential(\n",
    "    [\n",
    "        model_pt,\n",
    "        layers.Dense(1),\n",
    "        layers.Activation(\"sigmoid\", dtype=tf.float32)\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer_pt = tf.keras.optimizers.Adam(0.00001)\n",
    "\n",
    "scaled_optimizer_pt = mixed_precision.LossScaleOptimizer(optimizer_pt)\n",
    "\n",
    "model_pt.compile(optimizer=scaled_optimizer_pt, run_eagerly=False, jit_compile=True,\n",
    "                 metrics=[\n",
    "                     tf.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                     tf.metrics.AUC(name='auc'),\n",
    "                     tf.metrics.Precision(name='precision'),\n",
    "                     tf.metrics.Recall(name='recall'),\n",
    "                 ],\n",
    "                 loss=\"binary_crossentropy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.558875700Z"
    }
   },
   "id": "a431de06517e1690"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_pt.fit(\n",
    "    validation_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=20,\n",
    "    initial_epoch=0,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "    ,\n",
    "    class_weight=class_weight\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.559881Z"
    }
   },
   "id": "417f3ef89628788a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_pt.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.561385700Z"
    }
   },
   "id": "6a4751691212a4e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_pt.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.563393400Z"
    }
   },
   "id": "b5ad78edfe346807"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_st.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.566394100Z"
    }
   },
   "id": "554e537d78be663"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T17:32:12.566394100Z"
    }
   },
   "id": "ae1ee7093777da8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
